{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from time import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.corpus import words\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from transformers import (\n",
    "                BertConfig, BertModel, BertTokenizer,\n",
    "              XLNetConfig, XLNetModel, XLNetTokenizer)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value all over the place to make this reproducible.\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    np.random.seed(seed)  # Numpy module.\n",
    "    random.seed(seed)  # Python random module.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "\n",
    "setup_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {}\n",
    "CONFIG['A_train_path'] = \"datasets/train/SemEval2018-T3-train-taskA_emoji.txt\"\n",
    "CONFIG['A_test_path'] = \"datasets/goldtest_TaskA/SemEval2018-T3_gold_test_taskA_emoji.txt\"\n",
    "CONFIG['B_train_path'] = \"datasets/train/SemEval2018-T3-train-taskB_emoji.txt\"\n",
    "CONFIG['B_test_path'] = \"datasets/goldtest_TaskB/SemEval2018-T3_gold_test_taskB_emoji.txt\"\n",
    "CONFIG['max_len'] = 128\n",
    "CONFIG['bert_models'] = ['bert-base-uncased', 'bert-base-cased', 'bert-large-uncased', 'bert-large-cased']\n",
    "CONFIG['xlnet_models'] = ['xlnet-base-cased', 'xlnet-large-cased']\n",
    "CONFIG['clfs'] = [('clf_RF', 'param_RF'), ('clf_NB', 'param_NB'), \n",
    "                     ('clf_LR', 'param_LR'), ('clf_SVM', 'param_SVM')]\n",
    "# Random Forest Clf\n",
    "CONFIG['param_RF'] = {\n",
    "    'n_estimators': [100, 1000],\n",
    "    'max_depth': [10, 50, 100, None]\n",
    "}\n",
    "CONFIG['clf_RF'] = RandomForestClassifier(oob_score=True, \n",
    "                        random_state=1, verbose=1, n_jobs=-1)\n",
    "# Naive Bayesian Clf\n",
    "CONFIG['param_NB'] = {}\n",
    "CONFIG['clf_NB'] = GaussianNB()\n",
    "\n",
    "# Logistic Regression Clf\n",
    "CONFIG['param_LR'] = {\n",
    "    'solver': ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "    'C': np.arange(0.01, 0.2, 0.01),\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "CONFIG['clf_LR'] = LogisticRegression(random_state=1, verbose=1, n_jobs=-1)\n",
    "\n",
    "# SVM Clf\n",
    "CONFIG['param_SVM'] = {\n",
    "    'C': np.arange(5, 11, 1),  \n",
    "    'gamma': [0.01, 0.1, 1, 10], \n",
    "#     'gamma': np.arange(0.05, 0.15, 0.02),\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "CONFIG['clf_SVM'] = SVC(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some util functions, just run it\n",
    "\n",
    "# get score\n",
    "def print_score(true, predicted, task='A'):\n",
    "    acc = calc_accuracy(true, predicted)\n",
    "    if task == \"A\":\n",
    "        p, r, f = precision_recall_fscore(true, predicted, beta=1, labels=[0,1], pos_label=1)\n",
    "    elif task == \"B\":\n",
    "        p, r, f = precision_recall_fscore(true, predicted, beta=1, labels=[0,1,2,3])\n",
    "    print(\"Accuracy:{0}\\nPrecision:{1}\\nRecall:{2}\\nF1-score:{3}\\n\".format(acc, p,r,f))\n",
    "            \n",
    "\n",
    "def calc_accuracy(true, predicted):\n",
    "    \"\"\"Calculates the accuracy of a (multiclass) classifier, defined as the fraction of correct classifications.\"\"\"\n",
    "    return sum([t==p for t,p in zip(true, predicted)]) / float(len(true))\n",
    "\n",
    "\n",
    "def precision_recall_fscore(true, predicted, beta=1, labels=None, pos_label=None, average=None, each=None):\n",
    "    \"\"\"Calculates the precision, recall and F-score of a classifier.\n",
    "    :param true: iterable of the true class labels\n",
    "    :param predicted: iterable of the predicted labels\n",
    "    :param beta: the beta value for F-score calculation\n",
    "    :param labels: iterable containing the possible class labels\n",
    "    :param pos_label: the positive label (i.e. 1 label for binary classification)\n",
    "    :param average: selects weighted, micro- or macro-averaged F-score\n",
    "    \"\"\"\n",
    "\n",
    "    # Build contingency table as ldict\n",
    "    ldict = {}\n",
    "    for l in labels:\n",
    "        ldict[l] = {\"tp\": 0., \"fp\": 0., \"fn\": 0., \"support\": 0.}\n",
    "\n",
    "    for t, p in zip(true, predicted):\n",
    "        if t == p:\n",
    "            ldict[t][\"tp\"] += 1\n",
    "        else:\n",
    "            ldict[t][\"fn\"] += 1\n",
    "            ldict[p][\"fp\"] += 1\n",
    "        ldict[t][\"support\"] += 1\n",
    "\n",
    "    # Calculate precision, recall and F-beta score per class\n",
    "    beta2 = beta ** 2\n",
    "    for l, d in ldict.items():\n",
    "        try:\n",
    "            ldict[l][\"precision\"] = d[\"tp\"]/(d[\"tp\"] + d[\"fp\"])\n",
    "        except ZeroDivisionError: ldict[l][\"precision\"] = 0.0\n",
    "        try: ldict[l][\"recall\"]    = d[\"tp\"]/(d[\"tp\"] + d[\"fn\"])\n",
    "        except ZeroDivisionError: ldict[l][\"recall\"]    = 0.0\n",
    "        try: ldict[l][\"fscore\"] = (1 + beta2) * (ldict[l][\"precision\"] * ldict[l][\"recall\"]) / (beta2 * ldict[l][\"precision\"] + ldict[l][\"recall\"])\n",
    "        except ZeroDivisionError: ldict[l][\"fscore\"] = 0.0\n",
    "    \n",
    "    if each:\n",
    "        return [ldict[l][\"fscore\"] for l in labels]\n",
    "    \n",
    "    # If there is only 1 label of interest, return the scores. No averaging needs to be done.\n",
    "    if pos_label:\n",
    "        d = ldict[pos_label]\n",
    "        return (d[\"precision\"], d[\"recall\"], d[\"fscore\"])\n",
    "    # If there are multiple labels of interest, macro-average scores.\n",
    "    else:\n",
    "        for label in ldict.keys():\n",
    "            avg_precision = sum(l[\"precision\"] for l in ldict.values()) / len(ldict)\n",
    "            avg_recall = sum(l[\"recall\"] for l in ldict.values()) / len(ldict)\n",
    "            avg_fscore = sum(l[\"fscore\"] for l in ldict.values()) / len(ldict)\n",
    "        return (avg_precision, avg_recall, avg_fscore)\n",
    "\n",
    "# get ids and masks\n",
    "def get_ids_mask(sents, tokenizer, max_len=None):\n",
    "    t_e = [tokenizer.encode_plus(sent, \n",
    "                              max_length = max_len,\n",
    "                              add_special_tokens = True,\n",
    "                              pad_to_max_length = 'right',\n",
    "#                                 return_tensors='pt',\n",
    "                             ) for sent in sents]\n",
    "    \n",
    "    input_ids, attention_masks = [], []    \n",
    "    \n",
    "    for x in t_e:\n",
    "        input_ids.append(x['input_ids'])\n",
    "        attention_masks.append(x['attention_mask'])\n",
    "    \n",
    "    return input_ids, attention_masks\n",
    "\n",
    "# format time for training time\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "def get_embedding(model_type, ids, masks, model):\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(ids, attention_mask=masks)[0]\n",
    "    # for BERT, CLS token is at the beginning.\n",
    "    # for XLNet, CLS token is at the last.\n",
    "    if model_type == 'BERT':\n",
    "        return last_hidden_states[:, 0, :].numpy()\n",
    "    elif model_type == 'XLNet':\n",
    "        return last_hidden_states[:, -1, :].numpy()\n",
    "    \n",
    "\n",
    "def score_optimization(clf, params, scoring, X_f, X_l, y_f, y_l, task='A', best=None):\n",
    "    search = GridSearchCV(estimator=clf, param_grid=params,\n",
    "            scoring=scoring, n_jobs=-1).fit(X_f, X_l)\n",
    "    print(\"Classifier:\", clf.__class__.__name__)\n",
    "    print(\"Best parameters:\",search.best_params_)\n",
    "    print(\"Best score:\", search.best_score_)\n",
    "    print_score(y_l, search.best_estimator_.predict(y_f), task=task)\n",
    "    if best:\n",
    "        print(precision_recall_fscore(y_l, search.best_estimator_.predict(y_f), \n",
    "                                beta=1, labels=[0,1,2,3], each=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_embedding(task='A', model_type='BERT', verbose=False):\n",
    "    df = pd.read_csv(CONFIG[task+'_train_path'], delimiter='\\t', index_col=0)\n",
    "    df_test = pd.read_csv(CONFIG[task+'_test_path'], delimiter='\\t', index_col=0)\n",
    "    \n",
    "    print('Training Dataset has {} sentences.'.format(df.shape[0]))\n",
    "    print('Test Dataset has {} sentences.'.format(df_test.shape[0]))\n",
    "    print('Running word embedding  method for Task ' + task + ' on ' + model_type)\n",
    "    \n",
    "    # data preprocessing\n",
    "    with open('normalized_sents.pickle', 'rb') as f:\n",
    "        tv_sents, test_sents = pickle.load(f)\n",
    "    tv_labels = df['Label'].values\n",
    "    test_labels = df_test['Label'].values\n",
    "        \n",
    "    #initialize tokenizer\n",
    "    tokenizers = {}\n",
    "    if model_type == 'BERT':\n",
    "        for name in CONFIG['bert_models']:\n",
    "            if 'uncased' in name:\n",
    "                tokenizers[name] =  BertTokenizer.from_pretrained(name, do_lower_case=True)\n",
    "            else:\n",
    "                tokenizers[name] =  BertTokenizer.from_pretrained(name)\n",
    "    elif model_type == 'XLNet':\n",
    "        for name in CONFIG['xlnet_models']:\n",
    "            tokenizers[name] = XLNetTokenizer.from_pretrained(name)\n",
    "    \n",
    "    for name, tokenizer in tokenizers.items():\n",
    "        tv_ids, tv_masks = get_ids_mask(tv_sents, tokenizer, max_len=CONFIG['max_len'])\n",
    "        test_ids, test_masks = get_ids_mask(test_sents, tokenizer, max_len=CONFIG['max_len'])\n",
    "        tv_ids = torch.tensor(tv_ids)\n",
    "        tv_masks = torch.tensor(tv_masks)\n",
    "        test_ids = torch.tensor(test_ids)\n",
    "        test_masks = torch.tensor(test_masks)\n",
    "        \n",
    "        # initialize model\n",
    "        if model_type == 'BERT':\n",
    "            model = BertModel.from_pretrained(name)\n",
    "        elif model_type == 'XLNet':\n",
    "            model = XLNetModel.from_pretrained(name)\n",
    "        \n",
    "        train_features = get_embedding(model_type, tv_ids, tv_masks, model)\n",
    "        test_features = get_embedding(model_type, test_ids, test_masks, model)\n",
    "        \n",
    "        print(\"The {} model's result for task {} is:\".format(name, task))\n",
    "        for clf in CONFIG['clfs']:\n",
    "            score_optimization(CONFIG[clf[0]], CONFIG[clf[1]],\n",
    "                'f1_macro', train_features, tv_labels, test_features, test_labels, task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset has 3817 sentences.\n",
      "Test Dataset has 784 sentences.\n",
      "Running word embedding  method for Task A on BERT\n"
     ]
    }
   ],
   "source": [
    "run_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset has 3817 sentences.\n",
      "Test Dataset has 784 sentences.\n",
      "Running word embedding  method for Task B on BERT\n",
      "The bert-base-uncased model's result for task B is:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 688 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RandomForestClassifier\n",
      "Best parameters: {'max_depth': 50, 'n_estimators': 1000}\n",
      "Best score: 0.3122865450515221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=56)]: Using backend ThreadingBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=56)]: Done  88 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=56)]: Done 338 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.6020408163265306\n",
      "Precision:0.2655629139072848\n",
      "Recall:0.32117258804723353\n",
      "F1-score:0.29035218414631514\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=56)]: Done 688 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=56)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: GaussianNB\n",
      "Best parameters: {}\n",
      "Best score: 0.33334208691576284\n",
      "Accuracy:0.3520408163265306\n",
      "Precision:0.3655702935387928\n",
      "Recall:0.41052297523970144\n",
      "F1-score:0.3276417932849872\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LogisticRegression\n",
      "Best parameters: {'C': 0.15000000000000002, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best score: 0.4191603574221504\n",
      "Accuracy:0.6415816326530612\n",
      "Precision:0.41010885709818634\n",
      "Recall:0.4273687670809055\n",
      "F1-score:0.4016495213645721\n",
      "\n",
      "[LibSVM]Classifier: SVC\n",
      "Best parameters: {'C': 9, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best score: 0.42620390564274213\n",
      "Accuracy:0.6466836734693877\n",
      "Precision:0.4146476888931776\n",
      "Recall:0.42534556131533213\n",
      "F1-score:0.40570721002563037\n",
      "\n",
      "The bert-base-cased model's result for task B is:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 688 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RandomForestClassifier\n",
      "Best parameters: {'max_depth': 50, 'n_estimators': 1000}\n",
      "Best score: 0.30916635548908966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=56)]: Using backend ThreadingBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=56)]: Done  88 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=56)]: Done 338 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=56)]: Done 688 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=56)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.5778061224489796\n",
      "Precision:0.25124569460390356\n",
      "Recall:0.29121332439540043\n",
      "F1-score:0.26578794814943196\n",
      "\n",
      "Classifier: GaussianNB\n",
      "Best parameters: {}\n",
      "Best score: 0.34281433630648817\n",
      "Accuracy:0.3239795918367347\n",
      "Precision:0.340660249651279\n",
      "Recall:0.40176063523184824\n",
      "F1-score:0.3070308172184094\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LogisticRegression\n",
      "Best parameters: {'C': 0.19, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best score: 0.41071756282784333\n",
      "Accuracy:0.5931122448979592\n",
      "Precision:0.37575315223830075\n",
      "Recall:0.38380476126922686\n",
      "F1-score:0.3685366031036099\n",
      "\n",
      "[LibSVM]Classifier: SVC\n",
      "Best parameters: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best score: 0.3944543342516971\n",
      "Accuracy:0.5956632653061225\n",
      "Precision:0.3898224964821764\n",
      "Recall:0.3743694283261698\n",
      "F1-score:0.35549642126960435\n",
      "\n",
      "The bert-large-uncased model's result for task B is:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 688 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RandomForestClassifier\n",
      "Best parameters: {'max_depth': 50, 'n_estimators': 1000}\n",
      "Best score: 0.31363534514288016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=56)]: Using backend ThreadingBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=56)]: Done  88 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=56)]: Done 338 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=56)]: Done 688 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=56)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.5892857142857143\n",
      "Precision:0.2568472906403941\n",
      "Recall:0.30991208167895634\n",
      "F1-score:0.2803395874568564\n",
      "\n",
      "Classifier: GaussianNB\n",
      "Best parameters: {}\n",
      "Best score: 0.3143430942289653\n",
      "Accuracy:0.2780612244897959\n",
      "Precision:0.29769728690635666\n",
      "Recall:0.32634544037731095\n",
      "F1-score:0.2543330195141147\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LogisticRegression\n",
      "Best parameters: {'C': 0.14, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best score: 0.4290042918184061\n",
      "Accuracy:0.6020408163265306\n",
      "Precision:0.4763340018818403\n",
      "Recall:0.42712129789979775\n",
      "F1-score:0.4231064933274708\n",
      "\n",
      "[LibSVM]Classifier: SVC\n",
      "Best parameters: {'C': 5, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best score: 0.4217034373308909\n",
      "Accuracy:0.6160714285714286\n",
      "Precision:0.5160989552533018\n",
      "Recall:0.4130050116383276\n",
      "F1-score:0.39466438003992205\n",
      "\n",
      "The bert-large-cased model's result for task B is:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 688 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RandomForestClassifier\n",
      "Best parameters: {'max_depth': 50, 'n_estimators': 1000}\n",
      "Best score: 0.2994102925349263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=56)]: Using backend ThreadingBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=56)]: Done  88 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=56)]: Done 338 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=56)]: Done 688 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=56)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.5829081632653061\n",
      "Precision:0.25223741979061126\n",
      "Recall:0.2903399422472026\n",
      "F1-score:0.2648541114058356\n",
      "\n",
      "Classifier: GaussianNB\n",
      "Best parameters: {}\n",
      "Best score: 0.3436632341795341\n",
      "Accuracy:0.34438775510204084\n",
      "Precision:0.3093406010867843\n",
      "Recall:0.3646877110728054\n",
      "F1-score:0.30558212829457765\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   19.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LogisticRegression\n",
      "Best parameters: {'C': 0.09, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best score: 0.4187757828399434\n",
      "Accuracy:0.6211734693877551\n",
      "Precision:0.40917812142038945\n",
      "Recall:0.4193330446704541\n",
      "F1-score:0.39236836403033587\n",
      "\n",
      "[LibSVM]Classifier: SVC\n",
      "Best parameters: {'C': 7, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best score: 0.42410458111778737\n",
      "Accuracy:0.6479591836734694\n",
      "Precision:0.4721850914110152\n",
      "Recall:0.4417489448010887\n",
      "F1-score:0.4211106318765043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_embedding(task='B', model_type='BERT', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset has 3817 sentences.\n",
      "Test Dataset has 784 sentences.\n",
      "Running word embedding  method for Task A on XLNet\n",
      "The xlnet-base-cased model's result for task A is:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 688 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RandomForestClassifier\n",
      "Best parameters: {'max_depth': 10, 'n_estimators': 1000}\n",
      "Best score: 0.6095089075139171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=56)]: Using backend ThreadingBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=56)]: Done  88 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=56)]: Done 338 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=56)]: Done 688 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=56)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.5982142857142857\n",
      "Precision:0.4936708860759494\n",
      "Recall:0.5016077170418006\n",
      "F1-score:0.49760765550239233\n",
      "\n",
      "Classifier: GaussianNB\n",
      "Best parameters: {}\n",
      "Best score: 0.5618199091246512\n",
      "Accuracy:0.5178571428571429\n",
      "Precision:0.37992831541218636\n",
      "Recall:0.3408360128617363\n",
      "F1-score:0.3593220338983051\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LogisticRegression\n",
      "Best parameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best score: 0.6019408787702122\n",
      "Accuracy:0.6364795918367347\n",
      "Precision:0.5329949238578681\n",
      "Recall:0.6752411575562701\n",
      "F1-score:0.5957446808510639\n",
      "\n",
      "[LibSVM]Classifier: SVC\n",
      "Best parameters: {'C': 5, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best score: 0.3501222378412452\n",
      "Accuracy:0.5994897959183674\n",
      "Precision:0.42105263157894735\n",
      "Recall:0.02572347266881029\n",
      "F1-score:0.04848484848484848\n",
      "\n",
      "The xlnet-large-cased model's result for task A is:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 688 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RandomForestClassifier\n",
      "Best parameters: {'max_depth': 50, 'n_estimators': 1000}\n",
      "Best score: 0.5968895475186066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=56)]: Using backend ThreadingBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=56)]: Done  88 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=56)]: Done 338 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=56)]: Done 688 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=56)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.6198979591836735\n",
      "Precision:0.5173333333333333\n",
      "Recall:0.6237942122186495\n",
      "F1-score:0.565597667638484\n",
      "\n",
      "Classifier: GaussianNB\n",
      "Best parameters: {}\n",
      "Best score: 0.5273893859028636\n",
      "Accuracy:0.5076530612244898\n",
      "Precision:0.33480176211453744\n",
      "Recall:0.24437299035369775\n",
      "F1-score:0.2825278810408922\n",
      "\n",
      "[LibLinear]Classifier: LogisticRegression\n",
      "Best parameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best score: 0.5923848781906138\n",
      "Accuracy:0.6352040816326531\n",
      "Precision:0.5318066157760815\n",
      "Recall:0.6720257234726688\n",
      "F1-score:0.59375\n",
      "\n",
      "[LibSVM]Classifier: SVC\n",
      "Best parameters: {'C': 5, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best score: 0.34174449416278385\n",
      "Accuracy:0.610969387755102\n",
      "Precision:0.7142857142857143\n",
      "Recall:0.03215434083601286\n",
      "F1-score:0.061538461538461535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_embedding(task='A', model_type='XLNet', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset has 3817 sentences.\n",
      "Test Dataset has 784 sentences.\n",
      "Running word embedding  method for Task B on XLNet\n",
      "The xlnet-base-cased model's result for task B is:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 688 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RandomForestClassifier\n",
      "Best parameters: {'max_depth': 50, 'n_estimators': 1000}\n",
      "Best score: 0.27982804241095466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=56)]: Using backend ThreadingBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=56)]: Done  88 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=56)]: Done 338 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=56)]: Done 688 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=56)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.5969387755102041\n",
      "Precision:0.2579940509388362\n",
      "Recall:0.2991414427886351\n",
      "F1-score:0.2727267267267267\n",
      "\n",
      "Classifier: GaussianNB\n",
      "Best parameters: {}\n",
      "Best score: 0.3360455883158313\n",
      "Accuracy:0.42346938775510207\n",
      "Precision:0.3128506961066301\n",
      "Recall:0.3470097169199043\n",
      "F1-score:0.3153322992796677\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   15.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LogisticRegression\n",
      "Best parameters: {'C': 0.03, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best score: 0.3701743885778144\n",
      "Accuracy:0.5459183673469388\n",
      "Precision:0.3906671117540151\n",
      "Recall:0.3898471002418662\n",
      "F1-score:0.38215866755481326\n",
      "\n",
      "[LibSVM]Classifier: SVC\n",
      "Best parameters: {'C': 5, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best score: 0.1671027386109298\n",
      "Accuracy:0.6033163265306123\n",
      "Precision:0.15082908163265307\n",
      "Recall:0.25\n",
      "F1-score:0.1881463802704853\n",
      "\n",
      "The xlnet-large-cased model's result for task B is:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 688 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RandomForestClassifier\n",
      "Best parameters: {'max_depth': 50, 'n_estimators': 1000}\n",
      "Best score: 0.26043754022936744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=56)]: Using backend ThreadingBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=56)]: Done  88 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=56)]: Done 338 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=56)]: Done 688 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=56)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.5625\n",
      "Precision:0.2227540500736377\n",
      "Recall:0.2629621512917032\n",
      "F1-score:0.23414749845105326\n",
      "\n",
      "Classifier: GaussianNB\n",
      "Best parameters: {}\n",
      "Best score: 0.1957215258379293\n",
      "Accuracy:0.2002551020408163\n",
      "Precision:0.2339479683781307\n",
      "Recall:0.26091005396125344\n",
      "F1-score:0.15746581716532895\n",
      "\n",
      "[LibLinear]Classifier: LogisticRegression\n",
      "Best parameters: {'C': 0.06999999999999999, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best score: 0.3492917097378613\n",
      "Accuracy:0.5267857142857143\n",
      "Precision:0.3704582472992329\n",
      "Recall:0.35271815174023063\n",
      "F1-score:0.34529889772017636\n",
      "\n",
      "[LibSVM]Classifier: SVC\n",
      "Best parameters: {'C': 5, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best score: 0.1671027386109298\n",
      "Accuracy:0.6033163265306123\n",
      "Precision:0.15082908163265307\n",
      "Recall:0.25\n",
      "F1-score:0.1881463802704853\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_embedding(task='B', model_type='XLNet', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_for_each(name, clf, model_type='BERT', verbose=False):\n",
    "    df = pd.read_csv(CONFIG['B_train_path'], delimiter='\\t', index_col=0)\n",
    "    df_test = pd.read_csv(CONFIG['B_test_path'], delimiter='\\t', index_col=0)\n",
    "    \n",
    "    print('Training Dataset has {} sentences.'.format(df.shape[0]))\n",
    "    print('Test Dataset has {} sentences.'.format(df_test.shape[0]))\n",
    "    \n",
    "    # data preprocessing\n",
    "    with open('normalized_sents.pickle', 'rb') as f:\n",
    "        tv_sents, test_sents = pickle.load(f)\n",
    "    tv_labels = df['Label'].values\n",
    "    test_labels = df_test['Label'].values\n",
    "        \n",
    "    #initialize tokenizer\n",
    "    if model_type == 'BERT':\n",
    "        if 'uncased' in name:\n",
    "            tokenizer =  BertTokenizer.from_pretrained(name, do_lower_case=True)\n",
    "        else:\n",
    "            tokenizer =  BertTokenizer.from_pretrained(name)\n",
    "    elif model_type == 'XLNet':\n",
    "        tokenizer= XLNetTokenizer.from_pretrained(name)\n",
    "    \n",
    "    tv_ids, tv_masks = get_ids_mask(tv_sents, tokenizer, max_len=CONFIG['max_len'])\n",
    "    test_ids, test_masks = get_ids_mask(test_sents, tokenizer, max_len=CONFIG['max_len'])\n",
    "    tv_ids = torch.tensor(tv_ids)\n",
    "    tv_masks = torch.tensor(tv_masks)\n",
    "    test_ids = torch.tensor(test_ids)\n",
    "    test_masks = torch.tensor(test_masks)\n",
    "\n",
    "    # initialize model\n",
    "    if model_type == 'BERT':\n",
    "        model = BertModel.from_pretrained(name)\n",
    "    elif model_type == 'XLNet':\n",
    "        model = XLNetModel.from_pretrained(name)\n",
    "\n",
    "    train_features = get_embedding(model_type, tv_ids, tv_masks, model)\n",
    "    test_features = get_embedding(model_type, test_ids, test_masks, model)\n",
    "\n",
    "    print(\"The {} model's result for task {} is:\".format(name, 'B'))\n",
    "    score_optimization(CONFIG[clf[0]], CONFIG[clf[1]],\n",
    "            'f1_macro', train_features, tv_labels, test_features, test_labels, task='B', best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset has 3817 sentences.\n",
      "Test Dataset has 784 sentences.\n",
      "The bert-large-uncased model's result for task B is:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 56 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LogisticRegression\n",
      "Best parameters: {'C': 0.14, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best score: 0.4290042918184061\n",
      "Accuracy:0.6020408163265306\n",
      "Precision:0.4763340018818403\n",
      "Recall:0.42712129789979775\n",
      "F1-score:0.4231064933274708\n",
      "\n",
      "[0.7270788912579956, 0.4784688995215311, 0.40579710144927533, 0.08108108108108107]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.4s finished\n"
     ]
    }
   ],
   "source": [
    "get_best_for_each('bert-large-uncased', ('clf_LR', 'param_LR'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
